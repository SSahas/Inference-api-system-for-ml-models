# tf_deploy

- > main.py is the fastapi file and payloads is another file which contain the parameters to call the different models deployed on truefoundry

- > Run the inference.py file, with this code we can send inputs for the models locally from our pc  and it gets the output just like huggingface inference api system.

- > Wrote fastapi service for three different pipelines "text-generation", "token-classification", "zer-shot-clssification".
